{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from data_utils import get_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (2358, 1000, 22) \n",
      "y_train: (2358,) \n",
      "X_val: (100, 1000, 22) \n",
      "y_val: (100,) \n",
      "X_test: (100, 1000, 22) \n",
      "y_test: (100,) \n"
     ]
    }
   ],
   "source": [
    "# Load data from all .mat files, combine them, eliminate EOG signals, shuffle and \n",
    "# seperate training data, validation data and testing data.\n",
    "# Also do mean subtraction on x.\n",
    "\n",
    "data = get_data('project_datasets',num_validation=100, num_test=100, subtract_mean=False, transpose=True)\n",
    "for k in data.keys():\n",
    "    print('{}: {} '.format(k, data[k].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class flatten to connect to FC layer\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H = x.size() # read in N, C, H\n",
    "        return x.view(N, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn x and y into torch type tensor\n",
    "\n",
    "N_train, C_train, H_train = data.get('X_train').shape\n",
    "N_val, C_val, H_val = data.get('X_val').shape\n",
    "N_test, C_test, H_test = data.get('X_test').shape\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "\n",
    "X_train = Variable(torch.Tensor(data.get('X_train'))).type(dtype)\n",
    "y_train = Variable(torch.Tensor(data.get('y_train'))).type(torch.LongTensor)\n",
    "X_val = Variable(torch.Tensor(data.get('X_val'))).type(dtype)\n",
    "y_val = Variable(torch.Tensor(data.get('y_val'))).type(torch.LongTensor)\n",
    "X_test = Variable(torch.Tensor(data.get('X_test'))).type(dtype)\n",
    "y_test = Variable(torch.Tensor(data.get('y_test'))).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for LSTM model\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    # input_size: number of EGG channels\n",
    "    # output_size: number of classes\n",
    "    # hidden_size: size of hidden layers in LSTM module\n",
    "    # num_layers: number of hidden layers in LSTM module\n",
    "    # dropout: non-zero value means applying dropout to hidden layers\n",
    "    def __init__(self, input_size, output_size, hidden_size, num_layers=1, dropout=0):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # 1-layer LSTM with same hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=1, dropout=dropout, batch_first=True)    \n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, x, y, hidden_init, T_length=1):\n",
    "        \n",
    "        # initialize hidden variable and state variable every run\n",
    "        h = hidden_init\n",
    "        c = hidden_init\n",
    "\n",
    "        N, _, _ = x.size()\n",
    "        out_lstm, (h,c) = self.lstm(x, (h,c))\n",
    "        score = self.output(out_lstm)\n",
    "        \n",
    "        # calculate the total loss at time interval of T_length\n",
    "        loss = 0\n",
    "        for t in np.arange(T_length):\n",
    "            yy = score[:,-(t+1),:].squeeze(1)\n",
    "            loss += self.loss_fn(yy,y)\n",
    "        # score[N,S,C]:\n",
    "        # N: batch_size(number of time series), S: length of time series, C: number of classes\n",
    "        return score[:,-1,:].squeeze(1), loss, (h,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decare a LSTM model\n",
    "\n",
    "N_train, S, input_size = X_train.size()\n",
    "output_size = 4\n",
    "hidden_size = 10\n",
    "num_layers = 1\n",
    "dropout = 0\n",
    "\n",
    "model = LSTM(input_size, output_size, hidden_size, num_layers, dropout)\n",
    "model.type(dtype)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Variable containing:\n",
      " 13.8172\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "1 Variable containing:\n",
      " 13.9316\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "2 Variable containing:\n",
      " 13.6295\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "3 Variable containing:\n",
      " 13.8565\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "4 Variable containing:\n",
      " 13.9447\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "5 Variable containing:\n",
      " 13.7460\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "6 Variable containing:\n",
      " 13.8537\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "7 Variable containing:\n",
      " 13.8180\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "8 Variable containing:\n",
      " 13.6898\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "9 Variable containing:\n",
      " 13.6236\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "10 Variable containing:\n",
      " 14.0200\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "11 Variable containing:\n",
      " 13.8360\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "12 Variable containing:\n",
      " 13.3437\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "13 Variable containing:\n",
      " 13.2212\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "14 Variable containing:\n",
      " 13.8092\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "15 Variable containing:\n",
      " 13.6336\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "16 Variable containing:\n",
      " 13.4757\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "17 Variable containing:\n",
      " 14.0126\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "18 Variable containing:\n",
      " 13.6109\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "19 Variable containing:\n",
      " 13.9505\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "20 Variable containing:\n",
      " 13.6394\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "21 Variable containing:\n",
      " 13.2934\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "22 Variable containing:\n",
      " 13.2935\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "23 Variable containing:\n",
      " 13.7074\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "24 Variable containing:\n",
      " 13.3876\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "25 Variable containing:\n",
      " 13.6445\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "26 Variable containing:\n",
      " 13.6270\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "27 Variable containing:\n",
      " 13.7410\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "28 Variable containing:\n",
      " 13.8480\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "29 Variable containing:\n",
      " 13.4501\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "30 Variable containing:\n",
      " 13.6833\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "31 Variable containing:\n",
      " 13.0322\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "32 Variable containing:\n",
      " 13.7306\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "33 Variable containing:\n",
      " 13.4570\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "34 Variable containing:\n",
      " 13.8859\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "35 Variable containing:\n",
      " 13.8370\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "36 Variable containing:\n",
      " 13.6867\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "37 Variable containing:\n",
      " 13.3735\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "38 Variable containing:\n",
      " 13.9304\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "39 Variable containing:\n",
      " 13.1624\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2836fb11715e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/g/Course/2017-2018_4th_year/2018_winter/ECE_239AS/Project/.env3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/g/Course/2017-2018_4th_year/2018_winter/ECE_239AS/Project/.env3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train through several iterations\n",
    "num_epoch = 1\n",
    "batch_size = 30\n",
    "\n",
    "T_num_epoch = 100\n",
    "T_batch_size = int(S/T_num_epoch)\n",
    "step = np.arange(0,N_train,batch_size)\n",
    "#step = np.append(step,N_train) #discard some data\n",
    "\n",
    "loss_his = []\n",
    "train_accu_his = []\n",
    "val_accu_his = []\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    for t in range(step.shape[0]-1):\n",
    "        N = step[t+1] - step[t]\n",
    "        for T_epoch in range(T_num_epoch):    \n",
    "            if T_epoch == 0: \n",
    "                hidden_init = Variable(torch.zeros(num_layers, int(N), hidden_size))\n",
    "\n",
    "            # calculate loss\n",
    "            X_train_sub = X_train[step[t]:step[t+1],:(T_epoch+1)*T_batch_size,:]    \n",
    "            y_train_pred, loss, _ = model.forward(X_train_sub, y_train[step[t]:step[t+1]], \n",
    "                                                     hidden_init, T_length=T_batch_size)\n",
    "            # backpropagation\n",
    "            model.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            # update parameters\n",
    "            optimizer.step()\n",
    "        print(t,loss)\n",
    "        \n",
    "    # calculate predicted value for validation\n",
    "    hidden_init = Variable(torch.zeros(num_layers, N_val, hidden_size))\n",
    "    y_val_pred,_,_ = model(X_val, y_val, hidden_init)\n",
    "\n",
    "    # training loss\n",
    "    print('Epoch ', epoch, ', loss is ', loss.data.numpy())\n",
    "    _, y_pred = torch.max(y_train_pred,1)\n",
    "    loss_his.append(loss.data.numpy())\n",
    "    \n",
    "    # training accuracy\n",
    "    train_accu = np.mean(y_pred.data.numpy() == \n",
    "                                       y_train.data[step[t]:step[t+1]].numpy())\n",
    "    print('Training accuracy', train_accu)\n",
    "    train_accu_his.append(train_accu)\n",
    "\n",
    "    # validation accuracy    \n",
    "    _, y_pred = torch.max(y_val_pred,1)\n",
    "    val_accu = np.mean(y_pred.data.numpy() ==  y_val.data.numpy())\n",
    "    print('Validation accuracy', val_accu, '\\n')   \n",
    "    val_accu_his.append(val_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(threshold=np.nan)\n",
    "y_temp = y_pred.data.numpy()\n",
    "#print(y_temp)\n",
    "np.isnan(np.sum(y_temp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea4c7c84e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training and validation history\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(loss_his, 'o')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(train_accu_his, '-o')\n",
    "plt.plot(val_accu_his, '-o')\n",
    "plt.legend(['train','val'], loc='upper left')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.26 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test set\n",
    "hidden_init = Variable(torch.zeros(num_layers, N_test, hidden_size))\n",
    "y_test_pred,_,_ = model(X_test,y_test.type(torch.LongTensor),hidden_init)\n",
    "  \n",
    "_, y_pred = torch.max(y_test_pred,1)\n",
    "test_accu = np.mean(y_pred.data.numpy() ==  y_test.data.numpy())\n",
    "print('Test accuracy', test_accu, '\\n')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
